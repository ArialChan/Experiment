# HACAModel
 Implementation of "Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning" (https://arxiv.org/abs/1804.05448)

 ### Requirements:
 * [tensorboardX](https://github.com/lanpa/tensorboardX)
 * [pytorch](https://pytorch.org)

 *Use example has been provided in **slurm.sh***

